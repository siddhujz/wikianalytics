# wikianalytics
Text Analysis of Wikipedia dump using Apache Spark, Amazon s3

This project is mainly focused on parsing of the wikipedia dump(around 58GB of raw text which split across 750 files of equal size) and analyzing the data. 

The code runs on Apache Spark and I have used Amazon EMR Cluster to run it. The date is available in Amazon s3.
